
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Fast, Perceptive Quadrupedal Locomotion in Complex Terrain</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://jonbarron.info/zipnerf/img/nottingham.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://jgkang1210.github.io/icra_hound/"/>
    <meta property="og:title" content="Fast, Perceptive Quadrupedal Locomotion in Complex Terrain" />
    <meta property="og:description" content="Control of full sized quadruped robot with vision pipeline." />

    <!-- <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields" />
    <meta name="twitter:description" content="Neural Radiance Field training can be accelerated through the use of grid-based representations in NeRF's learned mapping from spatial coordinates to colors and volumetric density. However, these grid-based approaches lack an explicit understanding of scale and therefore often introduce aliasing, usually in the form of jaggies or missing scene content. Anti-aliasing has previously been addressed by mip-NeRF 360, which reasons about sub-volumes along a cone rather than points along a ray, but this approach is not natively compatible with current grid-based techniques. We show how ideas from rendering and signal processing can be used to construct a technique that combines mip-NeRF 360 and grid-based models such as Instant NGP to yield error rates that are 8%-77% lower than either prior technique, and that trains 24x faster than mip-NeRF 360." />
    <meta name="twitter:image" content="https://jonbarron.info/zipnerf/img/teaser.jpg" /> -->


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>âš¡</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    
    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Fast, Perceptive Quadrupedal Locomotion in Complex Terrain</br> 
                <small>
                ICRA Workshop 2024
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://jgkang1210.github.io/">
                          Jun-Gill Kang 1
                        </a>
                    </li>
                    <li>
                        JaeHyun Park 2
                    </li>
                    <li>
                        Tae-Gyu Song 2
                    </li>
                    <li>
                        Hae-Won Park 2
                    </li>
                    </br>1 ADD, 2 KAIST
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-6 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <!-- <li>
                            <a href=https://ieeexplore.ieee.org/abstract/document/10341386">
                            <image src="img/zip_paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li> -->
                        <li>
                            <a href="https://youtu.be/zqrd2cBLFrE?si=FhHYd1u5N1jroeWS">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    We present APT-RL(Action Pretrained Transformer based Reinforcement Learning) which achieves highspeed vision-based quadrupedal locomotion over complex terrain by encompassing two main quadruped locomotion skills, trotting and bounding. Unlike traditional pretraining-based reinforcement learning controllers, APT-RL does not rely on the acquisition of costly motion capture datasets or highly specialized policies for distinct tasks. Instead, it leverages a 2D simplified quadrupedal running dataset on flat terrain, coupled with a straightforward and cost-effective trajectory optimization technique. Our rigorous evaluation in real-world scenarios with the KAIST Hound, a 45kg full-sized quadrupedal robot, yielded experimental results including climbing over 60 centimeters high step at a speed of 4 meters per second while leveraging various gaits.
                </p>
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Gait change to overcome high obstacle
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/BlR_Twqn7ik?list=PLBNfPyVh4RiHCt_UGkd1wNGzNNhOo5LQn" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Indoor hurdle and high stair
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/lFRcQDZhvhU?list=PLBNfPyVh4RiHCt_UGkd1wNGzNNhOo5LQn" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
        <br>   
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Outdoor hurdle and step
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/zqrd2cBLFrE?list=PLBNfPyVh4RiHCt_UGkd1wNGzNNhOo5LQn" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
        <br> 
        
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Outdoor running experiment
                </h3>
                <div class="text-center">
                    <div style="position:relative;padding-top:56.25%;">
                        <iframe src="https://www.youtube.com/embed/N5FnkAPD-4U?list=PLBNfPyVh4RiHCt_UGkd1wNGzNNhOo5LQn" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                    </div>
                </div>
            </div>
        </div>
        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Demonstration in front of Marc Raibert at Hubo Lab KAIST! <a href="https://www.dynamicrobot.kaist.ac.kr" target="_blank">DRCD Lab</a>, <a href="https://www.railab.kaist.ac.kr/" target="_blank">RAI Lab</a>
                </h3>
                <div class="text-center">
                    <img src="img/raibert.JPG" width=100%>
                </div>
            </div>
        </div>
        <br>
        <br>

        

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@INPROCEEDINGS{10341386,
author={Kang, Jun-Gill and Lee, Dohyeon and Han, Soohee}, booktitle={2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, title={A Highly Maneuverable Flying Squirrel Drone with Controllable Foldable Wings}, year={2023}, volume={}, number={}, pages={6652-6659}, keywords={Drag;Biomimetics;Force;Rotors;Reinforcement learning;Aerodynamics;Mathematical models;Flying squirrel;quadrotor;drone;biomimetics;reinforcement learning;learning from demonstration}, doi={10.1109/IROS55552.2023.10341386}}
</textarea>
                </div>
            </div>
        </div> -->

        <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                Thanks to Janne Kontkanen, Rick Szeliski, and David Salesin for their comments on the text, and to Ricardo Martin-Brualla, Keunhong Park, Ben Poole, Aleksander HoÅ‚yÅ„ski, Etienne Pot, Kostas Rematas, Daniel Duckworth, Marcos Seefelder, Cardin Moffett, and Peter Zhizhin for their advice and help.
                    <br><br>
                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a> and <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>.
                </p>
            </div>
        </div> -->
    </div>
</body>
</html>
